"""
AI DECLARANT - Data Processor
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å AI –∞–≥–µ–Ω—Ç–æ–º
"""

import asyncio
import pandas as pd
import streamlit as st
from typing import Dict, List, Optional, Callable, Any
from datetime import datetime
import io
import config
import numpy as np
from ai_agents.hs_agent import HSCodeAgent
from database_manager import DatabaseManager
import time

from ai_agents.hs_agent import (
    HSCodeAgent, 
    HSCodeSearchResult, 
    BatchProcessingResult
)


class DataProcessor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–∞–Ω–Ω—ã—Ö"""
        self.current_data = None
        self.column_mapping = {}
        self.agent = None
        self.db_manager = DatabaseManager()  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ë–î
        print("üìä DataProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ë–î")
        self.hs_agent = HSCodeAgent()
        self.supported_formats = config.SUPPORTED_FILE_TYPES
        self.max_rows = config.MAX_ROWS_PER_FILE
    
    def validate_file(self, uploaded_file) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        
        Args:
            uploaded_file: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–∑ Streamlit
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        validation_result = {
            "is_valid": False,
            "error_message": "",
            "file_info": {},
            "warnings": []
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size_mb = uploaded_file.size / (1024 * 1024)
            if file_size_mb > config.MAX_FILE_SIZE_MB:
                validation_result["error_message"] = f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size_mb:.1f} MB). –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {config.MAX_FILE_SIZE_MB} MB"
                return validation_result
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            file_extension = uploaded_file.name.split('.')[-1].lower()
            if file_extension not in self.supported_formats:
                validation_result["error_message"] = f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: .{file_extension}. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(self.supported_formats)}"
                return validation_result
            
            # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
            validation_result["file_info"] = {
                "name": uploaded_file.name,
                "size_mb": round(file_size_mb, 2),
                "format": file_extension.upper(),
                "upload_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            validation_result["is_valid"] = True
            
        except Exception as e:
            validation_result["error_message"] = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"
        
        return validation_result
    
    def load_data(self, uploaded_file) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
        
        Args:
            uploaded_file: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–∑ Streamlit
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –∏ –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        result = {
            "success": False,
            "data": None,
            "error_message": "",
            "file_info": {},
            "sample_data": None
        }
        
        try:
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ñ–∞–π–ª
            validation = self.validate_file(uploaded_file)
            if not validation["is_valid"]:
                result["error_message"] = validation["error_message"]
                return result
            
            result["file_info"] = validation["file_info"]
            
            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            if file_extension == 'csv':
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è CSV
                encodings = ['utf-8', 'windows-1251', 'cp1252', 'iso-8859-1']
                data = None
                
                for encoding in encodings:
                    try:
                        uploaded_file.seek(0)  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —É–∫–∞–∑–∞—Ç–µ–ª—å —Ñ–∞–π–ª–∞
                        data = pd.read_csv(uploaded_file, encoding=encoding)
                        break
                    except UnicodeDecodeError:
                        continue
                
                if data is None:
                    result["error_message"] = "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É CSV —Ñ–∞–π–ª–∞"
                    return result
                    
            elif file_extension in ['xlsx', 'xls']:
                try:
                    uploaded_file.seek(0)
                    data = pd.read_excel(uploaded_file)
                except Exception as e:
                    result["error_message"] = f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Excel —Ñ–∞–π–ª–∞: {str(e)}"
                    return result
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
            if len(data) > self.max_rows:
                result["error_message"] = f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å—Ç—Ä–æ–∫ ({len(data)}). –ú–∞–∫—Å–∏–º—É–º: {self.max_rows}"
                return result
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—É—Å—Ç—ã–µ
            if data.empty:
                result["error_message"] = "–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö"
                return result
            
            # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            data = self._clean_data(data)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            sample_size = min(10, len(data))
            sample_data = data.head(sample_size)
            
            result.update({
                "success": True,
                "data": data,
                "sample_data": sample_data,
                "file_info": {
                    **result["file_info"],
                    "rows_count": len(data),
                    "columns_count": len(data.columns),
                    "columns": list(data.columns)
                }
            })
            
        except Exception as e:
            result["error_message"] = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
        
        return result
    
    def _clean_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        –û—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        
        Args:
            data: –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
            
        Returns:
            –û—á–∏—â–µ–Ω–Ω—ã–π DataFrame
        """
        # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        data = data.dropna(how='all')
        
        # –û–±—Ä–µ–∑–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
        text_columns = data.select_dtypes(include=['object']).columns
        data[text_columns] = data[text_columns].apply(lambda x: x.str.strip() if x.dtype == "object" else x)
        
        # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π
        data[text_columns] = data[text_columns].fillna('')
        
        return data
    
    def map_columns(self, data: pd.DataFrame, column_mapping: Dict[str, str]) -> pd.DataFrame:
        """
        –ú–∞–ø–ø–∏—Ç –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º—É –≤—ã–±–æ—Ä—É
        
        Args:
            data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            column_mapping: –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫ {–∏—Å—Ö–æ–¥–Ω–∞—è_–∫–æ–ª–æ–Ω–∫–∞: —Ü–µ–ª–µ–≤–∞—è_–∫–æ–ª–æ–Ω–∫–∞}
            
        Returns:
            DataFrame —Å –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
        """
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
        mapped_data = data.copy()
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –º–∞–ø–ø–∏–Ω–≥—É
        reverse_mapping = {v: k for k, v in column_mapping.items() if v and v != "–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å"}
        
        if reverse_mapping:
            mapped_data = mapped_data.rename(columns=reverse_mapping)
        
        return mapped_data
    
    def prepare_items_for_processing(self, data: pd.DataFrame, column_mapping: Dict[str, str]) -> List[Dict[str, str]]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ AI –∞–≥–µ–Ω—Ç–æ–º
        
        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            column_mapping: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è AI –∞–≥–µ–Ω—Ç–∞
        """
        print(f"üîß [DEBUG] prepare_items_for_processing: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(data)} —Å—Ç—Ä–æ–∫")
        print(f"üóÇÔ∏è [DEBUG] –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫: {column_mapping}")
        
        items = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–ª–∞–≤–Ω—É—é –∫–æ–ª–æ–Ω–∫—É —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ç–æ–≤–∞—Ä–∞
        main_column = None
        for target, source in column_mapping.items():
            if target == "product_name" and source:
                main_column = source
                break
        
        if not main_column:
            print("‚ùå [DEBUG] –ì–ª–∞–≤–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ç–æ–≤–∞—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≥–ª–∞–≤–Ω—É—é –∫–æ–ª–æ–Ω–∫—É —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ç–æ–≤–∞—Ä–∞")
        
        print(f"üìù [DEBUG] –ì–ª–∞–≤–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: '{main_column}'")
        
        # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        for index, row in data.iterrows():
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏
            main_value = row.get(main_column, '')
            if pd.isna(main_value):
                main_value = ''
            product_name = str(main_value).strip()
            
            if not product_name:
                print(f"‚ö†Ô∏è [DEBUG] –°—Ç—Ä–æ–∫–∞ {index}: –ø—É—Å—Ç–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            item = {
                "row_index": index,
                "product_name": product_name
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥—Ä—É–≥–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
            for target, source in column_mapping.items():
                if source and source != "–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å" and source != main_column and source in data.columns:
                    raw_value = row.get(source, '')
                    if pd.isna(raw_value):
                        raw_value = ''
                    value = str(raw_value).strip()
                    if value:
                        item[target] = value
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            for col in data.columns:
                if col not in column_mapping.values() and col != main_column:
                    raw_value = row.get(col, '')
                    if pd.isna(raw_value):
                        raw_value = ''
                    value = str(raw_value).strip()
                    if value and value.lower() not in ['nan', 'none', 'null']:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ –∫–∞–∫ –∫–ª—é—á
                        clean_key = col.lower().replace(' ', '_').replace('-', '_')
                        item[clean_key] = value
            
            print(f"  ‚úÖ [DEBUG] –≠–ª–µ–º–µ–Ω—Ç {len(items) + 1}: {item}")
            items.append(item)
        
        print(f"üéØ [DEBUG] –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ AI –∞–≥–µ–Ω—Ç–æ–º")
        return items
    
    async def process_data_with_ai(
        self, 
        data: pd.DataFrame, 
        column_mapping: Dict[str, str],
        filename: str = "unknown_file",
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é AI –∞–≥–µ–Ω—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
        
        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            column_mapping: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
            progress_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ session_id
        """
        print(f"üöÄ [DEBUG] –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞: {filename}")
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –≤ –ë–î
        session_id = self.db_manager.create_processing_session(
            filename=filename,
            total_items=len(data)
        )
        print(f"üìä [DEBUG] –°–æ–∑–¥–∞–Ω–∞ —Å–µ—Å—Å–∏—è –ë–î: {session_id}")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            items = self.prepare_items_for_processing(data, column_mapping)
            
            if not items:
                print("‚ùå [ERROR] –ù–µ—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                self.db_manager.update_processing_session(
                    session_id=session_id,
                    status='failed'
                )
                return {"success": False, "error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", "session_id": session_id}
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –ø–æ–º–æ—â—å—é AI –∞–≥–µ–Ω—Ç–∞
            batch_result = await self.hs_agent.classify_batch(items, progress_callback)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ (BatchProcessingResult –Ω–µ –∏–º–µ–µ—Ç success)
            if not batch_result.results or len(batch_result.errors) > 0:
                error_msg = f"–û—à–∏–±–∫–∞ AI –∞–≥–µ–Ω—Ç–∞: {'; '.join(batch_result.errors)}" if batch_result.errors else "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
                print(f"‚ùå [ERROR] {error_msg}")
                self.db_manager.update_processing_session(
                    session_id=session_id,
                    status='failed'
                )
                return {
                    "success": False, 
                    "error": error_msg,
                    "session_id": session_id
                }
            
            # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            results_df = self.create_results_dataframe(data, batch_result)
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ processing_stats
            stats = batch_result.processing_stats
            confidence_stats = {
                'high': stats.get('high_confidence_results', 0),
                'medium': stats.get('successful_classifications', 0) - stats.get('high_confidence_results', 0),
                'low': stats.get('total_items', 0) - stats.get('successful_classifications', 0)
            }
            processing_time = time.time() - start_time
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é –≤ –ë–î
            self.db_manager.update_processing_session(
                session_id=session_id,
                processed_items=len(batch_result.results),
                high_confidence=confidence_stats['high'],
                medium_confidence=confidence_stats['medium'],
                low_confidence=confidence_stats['low'],
                processing_time=processing_time,
                status='completed'
            )
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
            db_results = []
            for i, ai_result in enumerate(batch_result.results):
                row_index = items[i].get('row_index', i) if i < len(items) else i
                original_row = data.iloc[row_index] if row_index < len(data) else pd.Series()
                
                # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                category = brand = additional_info = ''
                
                for target, source in column_mapping.items():
                    if source and source in original_row.index:
                        value = str(original_row.get(source, '')).strip()
                        if target == 'category':
                            category = value
                        elif target == 'brand':
                            brand = value
                        elif target == 'additional_info':
                            additional_info = value
                
                db_result = {
                    'row_index': row_index,
                    'product_name': items[i].get('product_name', ''),
                    'original_description': ai_result.description or '',
                    'category': category,
                    'brand': brand,
                    'additional_info': additional_info,
                    'hs_code': ai_result.hs_code,
                    'confidence_percentage': ai_result.confidence,
                    'ai_reasoning': ai_result.reasoning,
                    'alternative_codes': getattr(ai_result, 'alternative_codes', [])
                }
                
                db_results.append(db_result)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î
            self.db_manager.save_classification_results(session_id, db_results)
            
            print(f"‚úÖ [SUCCESS] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f}—Å, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î")
            
            return {
                "success": True,
                "results": [
                    {
                        'row_index': i,
                        'product_name': items[i].get('product_name', ''),
                        'hs_code': result.hs_code,
                        'confidence_percentage': result.confidence,
                        'reasoning': result.reasoning,
                        'alternative_codes': getattr(result, 'alternative_codes', [])
                    }
                    for i, result in enumerate(batch_result.results)
                ],
                "dataframe": results_df,
                "statistics": confidence_stats,
                "processing_time": processing_time,
                "session_id": session_id
            }
            
        except Exception as e:
            print(f"‚ùå [EXCEPTION] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
            self.db_manager.update_processing_session(
                session_id=session_id,
                status='failed'
            )
            return {
                "success": False, 
                "error": str(e), 
                "session_id": session_id
            }
    
    def calculate_confidence_stats(self, results: List[Dict]) -> Dict[str, int]:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —É—Ä–æ–≤–Ω—è–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        stats = {'high': 0, 'medium': 0, 'low': 0}
        
        for result in results:
            confidence = result.get('confidence_percentage', 0)
            if confidence >= 80:
                stats['high'] += 1
            elif confidence >= 40:
                stats['medium'] += 1
            else:
                stats['low'] += 1
        
        return stats
    
    def prepare_results_for_db(
        self, 
        original_data: pd.DataFrame, 
        ai_results: List[Dict], 
        column_mapping: Dict[str, str]
    ) -> List[Dict]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î"""
        db_results = []
        
        for ai_result in ai_results:
            row_index = ai_result.get('row_index', 0)
            original_row = original_data.iloc[row_index] if row_index < len(original_data) else pd.Series()
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            category = ''
            brand = ''
            additional_info = ''
            
            for target, source in column_mapping.items():
                if source and source in original_data.columns:
                    value = str(original_row.get(source, '')).strip()
                    if target == 'category':
                        category = value
                    elif target == 'brand':
                        brand = value
                    elif target == 'additional_info':
                        additional_info = value
            
            db_result = {
                'row_index': row_index,
                'product_name': ai_result.get('product_name', ''),
                'original_description': ai_result.get('original_description', ''),
                'category': category,
                'brand': brand,
                'additional_info': additional_info,
                'hs_code': ai_result.get('hs_code', ''),
                'confidence_percentage': ai_result.get('confidence_percentage', 0),
                'ai_reasoning': ai_result.get('reasoning', ''),
                'alternative_codes': ai_result.get('alternative_codes', [])
            }
            
            db_results.append(db_result)
        
        return db_results
    
    def create_results_dataframe(
        self, 
        original_data: pd.DataFrame, 
        processing_results: BatchProcessingResult
    ) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        
        Args:
            original_data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            processing_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ AI –∞–≥–µ–Ω—Ç–æ–º
            
        Returns:
            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        results_df = original_data.copy()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        hs_codes = []
        confidences = []
        descriptions = []
        reasonings = []
        alternative_codes = []
        
        for result in processing_results.results:
            hs_codes.append(result.hs_code)
            confidences.append(result.confidence)
            descriptions.append(result.description)
            reasonings.append(result.reasoning)
            alternative_codes.append(", ".join(result.alternative_codes))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        results_df['–ö–æ–¥ –¢–ù –í–≠–î'] = hs_codes
        results_df['–£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è'] = confidences
        results_df['–û–ø–∏—Å–∞–Ω–∏–µ –¢–ù –í–≠–î'] = descriptions
        results_df['–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ'] = reasonings
        results_df['–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–¥—ã'] = alternative_codes
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π
        confidence_status = []
        for conf in confidences:
            if conf >= config.DEFAULT_CONFIDENCE_THRESHOLD:
                confidence_status.append("üü¢ –í—ã—Å–æ–∫–∏–π")
            elif conf >= config.MIN_CONFIDENCE_THRESHOLD:
                confidence_status.append("üü° –°—Ä–µ–¥–Ω–∏–π")
            else:
                confidence_status.append("üî¥ –ù–∏–∑–∫–∏–π")
        
        results_df['–°—Ç–∞—Ç—É—Å –¥–æ–≤–µ—Ä–∏—è'] = confidence_status
        
        return results_df
    
    def export_results(self, results_df: pd.DataFrame, format: str = "xlsx") -> bytes:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        
        Args:
            results_df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            format: –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ ('xlsx' –∏–ª–∏ 'csv')
            
        Returns:
            –ë–∞–π—Ç—ã —Ñ–∞–π–ª–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        """
        if format.lower() == "xlsx":
            # –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                results_df.to_excel(writer, index=False, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏')
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç—ã –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                workbook = writer.book
                worksheet = writer.sheets['–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏']
                
                # –§–æ—Ä–º–∞—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π –¥–æ–≤–µ—Ä–∏—è
                high_confidence_format = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})
                medium_confidence_format = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C6500'})
                low_confidence_format = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Å–ª–æ–≤–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                confidence_col = results_df.columns.get_loc('–£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è')
                worksheet.conditional_format(
                    1, confidence_col, len(results_df), confidence_col,
                    {'type': 'cell', 'criteria': '>=', 'value': config.DEFAULT_CONFIDENCE_THRESHOLD, 'format': high_confidence_format}
                )
                worksheet.conditional_format(
                    1, confidence_col, len(results_df), confidence_col,
                    {'type': 'cell', 'criteria': 'between', 'minimum': config.MIN_CONFIDENCE_THRESHOLD, 'maximum': config.DEFAULT_CONFIDENCE_THRESHOLD - 1, 'format': medium_confidence_format}
                )
                worksheet.conditional_format(
                    1, confidence_col, len(results_df), confidence_col,
                    {'type': 'cell', 'criteria': '<', 'value': config.MIN_CONFIDENCE_THRESHOLD, 'format': low_confidence_format}
                )
                
                # –ê–≤—Ç–æ–ø–æ–¥–≥–æ–Ω–∫–∞ —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
                for idx, col in enumerate(results_df.columns):
                    max_length = max(results_df[col].astype(str).map(len).max(), len(col)) + 2
                    worksheet.set_column(idx, idx, min(max_length, 50))
            
            return output.getvalue()
            
        elif format.lower() == "csv":
            # –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
            return results_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
        
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞: {format}")

    def create_dataframe_with_db_results(self, session_id: int) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–µ—Ç DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏, –≤–∫–ª—é—á–∞—è result_id –¥–ª—è —Å–≤—è–∑–∏ —Å –ë–î
        """
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –ë–î
        db_results = self.db_manager.get_session_results(session_id)
        
        if db_results.empty:
            return pd.DataFrame()
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        results_df = pd.DataFrame()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∫—Ä—ã—Ç—É—é –∫–æ–ª–æ–Ω–∫—É —Å result_id –¥–ª—è —Å–≤—è–∑–∏ —Å –ë–î
        results_df['_result_id'] = db_results['id']
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Ç–æ–≤–∞—Ä–∞
        results_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'] = db_results['product_name']
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –µ—Å–ª–∏ –µ—Å—Ç—å
        if not db_results['original_description'].isna().all():
            results_df['–û–ø–∏—Å–∞–Ω–∏–µ'] = db_results['original_description']
        if not db_results['category'].isna().all():
            results_df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] = db_results['category']
        if not db_results['brand'].isna().all():
            results_df['–ë—Ä–µ–Ω–¥'] = db_results['brand']
        if not db_results['additional_info'].isna().all():
            results_df['–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'] = db_results['additional_info']
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        results_df['–ö–æ–¥ –¢–ù –í–≠–î'] = db_results['hs_code']
        results_df['–£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è'] = db_results['confidence_percentage']
        results_df['–û–ø–∏—Å–∞–Ω–∏–µ –¢–ù –í–≠–î'] = db_results['original_description']  # –ó–∞–≥–ª—É—à–∫–∞, –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∞—Ç—å –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞
        results_df['–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ'] = db_results['ai_reasoning']
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–¥—ã
        alt_codes = []
        for codes in db_results['alternative_codes']:
            if isinstance(codes, list) and codes:
                alt_codes.append(", ".join(codes))
            else:
                alt_codes.append("")
        results_df['–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–¥—ã'] = alt_codes
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π
        confidence_status = []
        for conf in db_results['confidence_percentage']:
            if conf >= config.DEFAULT_CONFIDENCE_THRESHOLD:
                confidence_status.append("üü¢ –í—ã—Å–æ–∫–∏–π")
            elif conf >= config.MIN_CONFIDENCE_THRESHOLD:
                confidence_status.append("üü° –°—Ä–µ–¥–Ω–∏–π")
            else:
                confidence_status.append("üî¥ –ù–∏–∑–∫–∏–π")
        
        results_df['–°—Ç–∞—Ç—É—Å –¥–æ–≤–µ—Ä–∏—è'] = confidence_status
        
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å—Ç–∞—Ç—É—Å—ã
        user_statuses = []
        for status in db_results['user_status']:
            if status == 'confirmed':
                user_statuses.append("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ")
            elif status == 'needs_review':
                user_statuses.append("‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏")
            elif status == 'rejected':
                user_statuses.append("‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω–æ")
            else:
                user_statuses.append("‚è≥ –û–∂–∏–¥–∞–µ—Ç")
        
        results_df['–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Å—Ç–∞—Ç—É—Å'] = user_statuses
        
        return results_df


class ProgressTracker:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    
    def __init__(self):
        self.progress_bar = None
        self.status_text = None
        self.current_progress = 0
        self.total_items = 0
    
    def initialize(self, total_items: int):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–∫–µ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.total_items = total_items
        self.current_progress = 0
        
        # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã Streamlit –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self.status_text = st.empty()
        self.progress_bar = st.progress(0)
        
        self.update_display()
    
    def update(self, processed_items: int, total_items: int = None):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å"""
        if total_items:
            self.total_items = total_items
        
        self.current_progress = processed_items
        self.update_display()
    
    def update_display(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        if self.progress_bar and self.status_text:
            progress_ratio = self.current_progress / self.total_items if self.total_items > 0 else 0
            
            self.progress_bar.progress(progress_ratio)
            self.status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.current_progress} –∏–∑ {self.total_items} –ø–æ–∑–∏—Ü–∏–π ({progress_ratio:.1%})")
    
    def complete(self):
        """–ó–∞–≤–µ—Ä—à–∞–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        if self.progress_bar and self.status_text:
            self.progress_bar.progress(1.0)
            self.status_text.text(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {self.total_items} –ø–æ–∑–∏—Ü–∏–π")
    
    def error(self, error_message: str):
        """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –æ—à–∏–±–∫—É"""
        if self.status_text:
            self.status_text.error(f"‚ùå –û—à–∏–±–∫–∞: {error_message}")


# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã
__all__ = [
    'DataProcessor',
    'ProgressTracker'
] 